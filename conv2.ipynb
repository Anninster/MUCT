{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second model: convolutions\n",
    "## Data augmentation, learning rate decay, dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nolearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-850035872891>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnolearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlasagne\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBatchIterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"done loading libraries\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nolearn'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg', warn = False)\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "from pandas import DataFrame\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nolearn.lasagne import BatchIterator\n",
    "import tensorflow as tf\n",
    "print(\"done loading libraries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paths to datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\FYP\\CNN\\muct-master\\allimger\\data\\train.csv\n",
      "D:\\FYP\\CNN\\muct-master\\allimger\\data\\test.csv\n"
     ]
    }
   ],
   "source": [
    "FROOT = os.getcwd() # Path to your project folder\n",
    "FTRAIN = FROOT + '\\data\\\\train.csv'\n",
    "print(FTRAIN)\n",
    "FTEST = FROOT + '\\data\\\\test.csv'\n",
    "print(FTEST)\n",
    "#FLOOKUP = FROOT + '/data/IdLookupTable.csv'\n",
    "Irows=640\n",
    "Icols=480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaley(y,rows,cols):\n",
    "\t#loop for rows\n",
    "\tdr=cols/2\n",
    "\tfor i in range(0,152,2):\n",
    "\t\ty[:,i]=y[:,i]/dr\n",
    "\t#loop for cols\n",
    "\tdc=rows/2\n",
    "\tfor i in range(1,152,2):\n",
    "\t\ty[:,i]=y[:,i]/dc\n",
    "\treturn y\n",
    "\n",
    "def load(test = False, cols = None):\n",
    "    \"\"\"\n",
    "    Loads the dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    test     : optional, defaults to `False`\n",
    "               Flag indicating if we need to load from `FTEST` (`True`) or FTRAIN (`False`)\n",
    "    cols     : optional, defaults to `None`\n",
    "               A list of columns you're interested in. If specified only returns these columns.\n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of X and y, if `test` was set to `True` y contains `None`.    \n",
    "    \"\"\"\n",
    "    \n",
    "    fname = FTEST if test else FTRAIN\n",
    "    df = read_csv(os.path.expanduser(fname))  # load pandas dataframe\n",
    "\n",
    "    # The Image column has pixel values separated by space; convert\n",
    "    # the values to numpy arrays:\n",
    "    df['image'] = df['image'].apply(lambda im: np.fromstring(im, sep = ','))\n",
    "\n",
    "    if cols:  # get a subset of columns\n",
    "        df = df[list(cols) + ['image']]\n",
    "\n",
    "    print(df.count())  # prints the number of values for each column\n",
    "    df = df.dropna()  # drop all rows that have missing values in them\n",
    "\n",
    "    X = np.vstack(df['image'].values) / 255.  # scale pixel values to [0, 1]\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    if not test:  # only FTRAIN has any target columns\n",
    "        y = df[df.columns[4:-1]].values\n",
    "        y = scaley(y,640,480)   #(y - 48) / 48   scale target coordinates to [-1, 1]\n",
    "        X, y = shuffle(X, y, random_state=42)  # shuffle train data\n",
    "        y = y.astype(np.float32)\n",
    "    else:\n",
    "        y = None\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(x, y, axis):\n",
    "    \"\"\"\n",
    "    Plots a single sample image with keypoints on top.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x     : \n",
    "            Image data.\n",
    "    y     : \n",
    "            Keypoints to plot.\n",
    "    axis  :\n",
    "            Plot over which to draw the sample.   \n",
    "    \"\"\"\n",
    "    img = x.reshape(Irows, Icols)\n",
    "    axis.imshow(img, cmap='gray')\n",
    "    axis.scatter(y[0::2] * 240 + 240, y[1::2] * 320 + 320, marker='x', s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = 1 # grayscale\n",
    "image_size = 96\n",
    "\n",
    "def load2d(test = False, cols = None):\n",
    "    X, y = load(test = test)\n",
    "    X = X.reshape(-1, Irows, Icols, num_channels)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done loading traing dataset\n"
     ]
    }
   ],
   "source": [
    "#X, y = load2d()\n",
    "print(\"done loading traing dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the initial training dataset into training, validation and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done spliting\n"
     ]
    }
   ],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "#x_test, x_valid, y_test, y_valid = train_test_split(x_test, y_test, test_size = 0.5)\n",
    "print(\"done spliting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our data augmentation routine. It randomly flips a defined portion of dataset horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FlipBatchIterator(BatchIterator):\n",
    "    \"\"\"\n",
    "    Batch iterator that randomly flips a defined portion of dataset horizontally.\n",
    "    \"\"\"\n",
    "    \n",
    "    flip_indices = [\n",
    "        (0,28),(1,29),(2,26),(3,27),(4,24),\n",
    "        (5,25),(6,22),(7,23),(8,20),(9,21),\n",
    "        (10,18),(11,19),(12,16),(13,17),(30,42),\n",
    "        (31,43),(32,44),(33,45),(34,46),(35,47),\n",
    "        (36,48),(37,49),(38,50),(39,51),(40,52),\n",
    "        (41,53),(54,64),(55,65),(56,66),(57,67),\n",
    "        (58,68),(59,69),(60,70),(61,71),(62,72),\n",
    "        (63,73),(74,90),(75,91),(76,88),(77,89),\n",
    "        (78,86),(79,87),(80,84),(81,85),(92,94),\n",
    "        (93,95),(96,108),(97,109),(98,106),(99,107),\n",
    "        (100,104),(101,105),(110,118),(111,119),\n",
    "        (112,116),(113,117),(120,124),(121,125),\n",
    "        (126,130),(127,131),(136,144),(137,145),\n",
    "        (138,146),(139,147),(140,148),(141,149),\n",
    "        (142,150),(143,151)\n",
    "        ]\n",
    "\n",
    "    def transform(self, Xb, yb):\n",
    "        Xb, yb = super(FlipBatchIterator, self).transform(Xb, yb)\n",
    "\n",
    "        # Flip half of the images in this batch at random:\n",
    "        bs = Xb.shape[0]\n",
    "        indices = np.random.choice(bs, int(bs / 2), replace=False)\n",
    "        Xb[indices] = Xb[indices, :, ::-1, :]\n",
    "\n",
    "        if yb is not None:\n",
    "            # Horizontal flip of all x coordinates:\n",
    "            yb[indices, ::2] = yb[indices, ::2] * -1\n",
    "\n",
    "            # Swap places, e.g. left_eye_center_x -> right_eye_center_x\n",
    "            for a, b in self.flip_indices:\n",
    "                yb[indices, a], yb[indices, b] = (\n",
    "                    yb[indices, b], yb[indices, a])\n",
    "\n",
    "        return Xb, yb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try flipping a sample batch of images and plot it to verify it's all good. What you should see is half of images flipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done line 10\n"
     ]
    }
   ],
   "source": [
    "#batch_iterator = FlipBatchIterator(batch_size = 10)\n",
    "#for x_batch, y_batch in batch_iterator(X.copy(), y.copy()):\n",
    "#    for i in range(1):        \n",
    "#        # plot two images:\n",
    "#        fig = pyplot.figure(figsize=(6, 3))\n",
    "#        ax = fig.add_subplot(1, 2, 1, xticks=[], yticks=[])\n",
    "#        plot_sample(X[i], y[i], ax)\n",
    "#        ax = fig.add_subplot(1, 2, 2, xticks=[], yticks=[])\n",
    "#        plot_sample(x_batch[i], y_batch[i], ax)\n",
    "#        pyplot.show()\n",
    "#    break\n",
    "print(\"done line 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predefined parameters\n",
    "num_keypoints = 152\n",
    "batch_size = 36\n",
    "num_epochs = 101\n",
    "\n",
    "data_augmentation = True\n",
    "learning_rate_decay = True\n",
    "momentum_increase = True\n",
    "dropout = True\n",
    "\n",
    "# We will encode model settings in its name: architecture, batch size, number of epochs and optimisations applied.\n",
    "model_name = \"MUCTmodel\"+\"_3con_2fc_b\" + str(batch_size) + \"_e\" + str(num_epochs - 1)\n",
    "if data_augmentation:\n",
    "    model_name += \"_aug\"\n",
    "if learning_rate_decay:\n",
    "    model_name += \"_lrdec\"\n",
    "if momentum_increase:\n",
    "    model_name += \"_mominc\"\n",
    "if dropout:\n",
    "    model_name += \"_dr\"\n",
    "    \n",
    "model_variable_scope = model_name\n",
    "root_location = FROOT + \"/models/\"\n",
    "model_path = root_location + model_name + \"/model.ckpt\"\n",
    "train_history_path = root_location + model_name + \"/train_history\"\n",
    "\n",
    "os.makedirs(root_location + model_name + \"/\", exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs a single fully connected layer pass, e.g. returns `input * weights + bias`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(input, size):\n",
    "    \"\"\"\n",
    "    Creates a fully connected TensorFlow layer.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input  : \n",
    "            Input tensor for calculating layer shape.\n",
    "    size   : \n",
    "            Layer size, e.g. number of units.\n",
    "               \n",
    "    Returns\n",
    "    -------\n",
    "    A graph variable calculating single fully connected layer.\n",
    "    \"\"\"\n",
    "    weights = tf.get_variable( 'weights', \n",
    "        shape = [input.get_shape()[1], size],\n",
    "        initializer = tf.contrib.layers.xavier_initializer()\n",
    "      )\n",
    "    biases = tf.get_variable( 'biases',\n",
    "        shape = [size],\n",
    "        initializer=tf.constant_initializer(0.0)\n",
    "      )\n",
    "    return tf.matmul(input, weights) + biases\n",
    "\n",
    "def fully_connected_relu(input, size):\n",
    "    \"\"\"\n",
    "    Creates a fully connected TensorFlow layer with ReLU non-linearity applied.\n",
    "    \"\"\"\n",
    "    return tf.nn.relu(fully_connected(input, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Routine for a single convolution layer pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_relu(input, kernel_size, depth):\n",
    "    \"\"\"\n",
    "    Creates a convolutional TensorFlow layer followed by a ReLU.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input         : \n",
    "                    Input tensor for calculating layer shape.\n",
    "    kernel_rsize   : \n",
    "                    Kernel row size.\n",
    "    kernel_csize   : \n",
    "                    Kernel column size.\n",
    "    depth         : \n",
    "                    Layer depth, e.g. number of units.\n",
    "               \n",
    "    Returns\n",
    "    -------\n",
    "    A graph variable calculating convolutional layer with applied ReLU.\n",
    "    \"\"\"\n",
    "    weights = tf.get_variable( 'weights', \n",
    "        shape = [kernel_size, kernel_size, input.get_shape()[3], depth],\n",
    "        initializer = tf.contrib.layers.xavier_initializer()\n",
    "      )\n",
    "    biases = tf.get_variable( 'biases',\n",
    "        shape = [depth],\n",
    "        initializer=tf.constant_initializer(0.0)\n",
    "      )\n",
    "    conv = tf.nn.conv2d(input, weights,\n",
    "        strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv + biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Routine for a pooling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool(input, size):\n",
    "    \"\"\"\n",
    "    Performs max pooling.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input  : \n",
    "            Input tensor.\n",
    "    rsize   : \n",
    "            Pooling kernel row size.\n",
    "    csize   : \n",
    "            Pooling kernel  column size.\n",
    "               \n",
    "    Returns\n",
    "    -------\n",
    "    A graph variable calculating single max pooling layer.\n",
    "    \"\"\"\n",
    "    return tf.nn.max_pool(\n",
    "        input, \n",
    "        ksize=[1, size, size, 1], \n",
    "        strides=[1, size, size, 1], \n",
    "        padding='SAME'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Routine that performs entire model pass, e.g. returns model prediction for given input with current model (3 convolution layers with 2 fully connected layers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pass(input, training):\n",
    "    \"\"\"\n",
    "    Performs a whole model pass.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input     : \n",
    "                Input tensor to be passed through the model.\n",
    "    training  : \n",
    "                Tensorflow flag indicating if we are training or evaluating our model \n",
    "                (so that we know if we should apply dropout).\n",
    "               \n",
    "    Returns\n",
    "    -------\n",
    "    Model prediction.\n",
    "    \"\"\"\n",
    "    # Convolutional layers\n",
    "    with tf.variable_scope('conv1'):\n",
    "        conv1 = conv_relu(input, kernel_size = 3, depth = 32) \n",
    "        pool1 = pool(conv1, size = 2)\n",
    "        # Apply dropout if needed\n",
    "        pool1 = tf.cond(training, lambda: tf.nn.dropout(pool1, keep_prob = 0.9 if dropout else 1.0), lambda: pool1)\n",
    "    with tf.variable_scope('conv2'):\n",
    "        conv2 = conv_relu(pool1, kernel_size = 2, depth = 64)\n",
    "        pool2 = pool(conv2, size = 2)\n",
    "        # Apply dropout if needed\n",
    "        pool2 = tf.cond(training, lambda: tf.nn.dropout(pool2, keep_prob = 0.8 if dropout else 1.0), lambda: pool2)\n",
    "    with tf.variable_scope('conv3'):\n",
    "        conv3 = conv_relu(pool2, kernel_size = 2, depth = 128)\n",
    "        pool3 = pool(conv3, size = 2)\n",
    "        # Apply dropout if needed\n",
    "        pool3 = tf.cond(training, lambda: tf.nn.dropout(pool3, keep_prob = 0.7 if dropout else 1.0), lambda: pool3)\n",
    "    \n",
    "    # Flatten convolutional layers output\n",
    "    shape = pool3.get_shape().as_list()\n",
    "    flattened = tf.reshape(pool3, [-1, shape[1] * shape[2] * shape[3]])\n",
    "    \n",
    "    # Fully connected layers\n",
    "    with tf.variable_scope('fc4'):\n",
    "        fc4 = fully_connected_relu(flattened, size = 1000)\n",
    "        # Apply dropout if needed\n",
    "        fc4 = tf.cond(training, lambda: tf.nn.dropout(fc4, keep_prob = 0.5 if dropout else 1.0), lambda: fc4)\n",
    "    with tf.variable_scope('fc5'):\n",
    "        fc5 = fully_connected_relu(fc4, size = 1000)\n",
    "    with tf.variable_scope('out'):\n",
    "        prediction = fully_connected(fc5, size = num_keypoints)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates loss based on model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(predictions, labels):\n",
    "    \"\"\"\n",
    "    Calculates loss with NumPy.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions : ndarray \n",
    "                  Predictions.\n",
    "    labels      : ndarray\n",
    "                  Actual values.\n",
    "               \n",
    "    Returns\n",
    "    -------\n",
    "    Squared mean error for given predictions.\n",
    "    \"\"\"\n",
    "    return np.mean(np.square(predictions - labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates time since `start` and formats as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_hhmmss(start):\n",
    "    \"\"\"\n",
    "    Calculates time since `start` and formats as a string.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    start :  \n",
    "            Time starting point.\n",
    "               \n",
    "    Returns\n",
    "    -------\n",
    "    Nicely formatted time difference between now and `start`.\n",
    "    \"\"\"\n",
    "    end = time.time()\n",
    "    m, s = divmod(end - start, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    time_str = \"%02d:%02d:%02d\" % (h, m, s)\n",
    "    return time_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "WARNING:tensorflow:From d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-15-737c1d2a5439>:22: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "print(\"start\")\n",
    "with graph.as_default():\n",
    "    # Input data. For the training data, we use a placeholder that will be fed at run time with a training minibatch.\n",
    "    tf_x_batch = tf.placeholder(tf.float32, shape = (None, Irows, Icols, num_channels))\n",
    "    tf_y_batch = tf.placeholder(tf.float32, shape = (None, num_keypoints))\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "    current_epoch = tf.Variable(0)  # count the number of epochs\n",
    "\n",
    "    # Model parameters.\n",
    "    \n",
    "    # Calculate learning rate decay if needed.\n",
    "    if learning_rate_decay:\n",
    "        learning_rate = tf.train.exponential_decay(0.03, current_epoch, decay_steps=num_epochs, decay_rate=0.03)\n",
    "    else:\n",
    "        learning_rate = 0.01\n",
    "        \n",
    "    # Calculate increasing momentum if needed.\n",
    "    if momentum_increase:\n",
    "        m_min = 0.9\n",
    "        m_max = 0.99\n",
    "        momentum = m_min + (m_max - m_min) * (current_epoch / num_epochs) \n",
    "    else:\n",
    "        momentum = 0.9\n",
    "    \n",
    "    # Training computation.\n",
    "    with tf.variable_scope(model_variable_scope):\n",
    "        predictions = model_pass(tf_x_batch, is_training)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.square(predictions - tf_y_batch))\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.MomentumOptimizer(\n",
    "        learning_rate = learning_rate, \n",
    "        momentum = momentum, \n",
    "        use_nesterov = True\n",
    "    ).minimize(loss)\n",
    "    \n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_in_batches(X, session):\n",
    "    \"\"\"\n",
    "    Calculates predictions in batches of 128 examples at a time, using `session`'s calculation graph.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X       : ndarray\n",
    "              Dataset to get predictions for.\n",
    "    session :\n",
    "              TensorFlow session to be used for predicting. Is expected to have a `predictions` var \n",
    "              in the graph along with a `tf_x_batch` placeholder for incoming data.\n",
    "               \n",
    "    Returns\n",
    "    -------\n",
    "    N-dimensional array of predictions.\n",
    "    \"\"\"\n",
    "    p = []\n",
    "    batch_iterator = BatchIterator(batch_size = 128)\n",
    "    for x_batch, _ in batch_iterator(X):\n",
    "        [p_batch] = session.run([predictions], feed_dict = {\n",
    "                tf_x_batch : x_batch,\n",
    "                is_training : False\n",
    "            }\n",
    "        )\n",
    "        p.extend(p_batch)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from D:\\FYP\\CNN\\muct-master\\allimger\\muctdata\\models\\MUCTmodel_3con_2fc_b36_e100_aug_lrdec_mominc_dr\\model.ckpt\n",
      "model restored\n",
      "prediction are: [array([[-4.09757018e-01,  9.70426947e-03, -4.20393825e-01,\n",
      "         1.00986220e-01, -4.03695345e-01,  1.92281395e-01,\n",
      "        -3.94951820e-01,  2.89573044e-01, -3.33921462e-01,\n",
      "         3.90932828e-01, -2.47292325e-01,  4.63322341e-01,\n",
      "        -1.32102624e-01,  4.98232961e-01, -2.77678668e-03,\n",
      "         5.16548872e-01,  1.22197241e-01,  4.99967843e-01,\n",
      "         2.39044249e-01,  4.56127167e-01,  3.28049630e-01,\n",
      "         3.96210134e-01,  3.85517359e-01,  2.95656800e-01,\n",
      "         4.05359030e-01,  1.99052751e-01,  4.10661906e-01,\n",
      "         1.06420457e-01,  4.05348420e-01,  9.70695913e-03,\n",
      "         3.07913005e-01, -4.51300740e-02,  2.36076683e-01,\n",
      "        -1.00042708e-01,  1.64960876e-01, -1.07555471e-01,\n",
      "         8.51064250e-02, -6.33961558e-02,  1.67819902e-01,\n",
      "        -7.34384358e-02,  2.39568233e-01, -7.12789744e-02,\n",
      "        -3.32991898e-01, -5.75358644e-02, -2.65245497e-01,\n",
      "        -1.12159632e-01, -1.78951755e-01, -9.77146626e-02,\n",
      "        -9.47979391e-02, -7.50247240e-02, -1.68786347e-01,\n",
      "        -6.14172891e-02, -2.60976851e-01, -6.40557706e-02,\n",
      "        -2.69603133e-01,  1.06885955e-02, -2.01534361e-01,\n",
      "        -3.11491489e-02, -1.36702031e-01, -7.06210732e-03,\n",
      "        -1.96867496e-01,  2.20097080e-02, -2.04457238e-01,\n",
      "        -3.62962484e-03,  2.58351833e-01,  6.42723963e-03,\n",
      "         1.85470685e-01, -2.33246684e-02,  1.20386943e-01,\n",
      "         1.62643753e-02,  1.83466583e-01,  2.01166198e-02,\n",
      "         1.75920084e-01, -1.80064514e-03, -5.19161709e-02,\n",
      "        -2.08392739e-03, -6.64531738e-02,  8.73062313e-02,\n",
      "        -1.32061288e-01,  1.46471098e-01, -1.02921456e-01,\n",
      "         1.72387436e-01, -4.98878676e-03,  1.89114764e-01,\n",
      "         8.46907645e-02,  1.78072408e-01,  1.24047495e-01,\n",
      "         1.60107255e-01,  4.91597354e-02,  7.61038586e-02,\n",
      "         3.67684551e-02, -8.58761743e-03, -6.68794215e-02,\n",
      "         1.62906080e-01,  5.44364527e-02,  1.67027846e-01,\n",
      "        -1.70320570e-01,  2.92100072e-01, -8.56053531e-02,\n",
      "         2.48706624e-01, -3.82498689e-02,  2.44515300e-01,\n",
      "        -9.85339284e-04,  2.53053755e-01,  3.32755595e-02,\n",
      "         2.38595724e-01,  8.30364153e-02,  2.47503877e-01,\n",
      "         1.64275065e-01,  2.90770352e-01,  1.12284400e-01,\n",
      "         3.23978782e-01,  5.86448647e-02,  3.38133574e-01,\n",
      "        -7.24326819e-05,  3.40419888e-01, -6.27292916e-02,\n",
      "         3.35660160e-01, -1.24834687e-01,  3.27322513e-01,\n",
      "        -7.44893625e-02,  3.00749660e-01, -3.60791618e-03,\n",
      "         3.05242926e-01,  6.36582449e-02,  3.05467218e-01,\n",
      "         6.20831288e-02,  2.75687933e-01,  3.59946163e-04,\n",
      "         2.71076620e-01, -7.22288936e-02,  2.77124465e-01,\n",
      "        -6.81039877e-03,  2.80366719e-01, -1.04997978e-02,\n",
      "         1.32265121e-01, -2.40868241e-01, -1.23999119e-02,\n",
      "        -1.68547601e-01, -3.69096547e-03, -1.59309924e-01,\n",
      "         1.35916397e-02, -2.34984308e-01,  9.64641571e-03,\n",
      "         2.10826397e-01, -1.13646574e-02,  1.50747448e-01,\n",
      "        -1.01066865e-02,  1.42133027e-01,  8.14022869e-03,\n",
      "         2.18659446e-01,  1.50137395e-02]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "every_epoch_to_log = 5\n",
    "\"\"\"\"\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "bag_file_path=\"test.bag\"\n",
    "\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "rs.config.enable_device_from_file(config, bag_file_path)\n",
    "config.enable_stream(rs.stream.depth)\n",
    "config.enable_stream(rs.stream.color)\n",
    "\n",
    "profile = pipeline.start(config)\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        aligned_frames = align.process(frames)\n",
    "        aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "        color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "        depth_image = np.asanyarray(aligned_depth_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "        num_rows = depth_image.shape[0]\n",
    "        num_cols = depth_image.shape[1]\n",
    "\n",
    "        depth_intrin = aligned_depth_frame.profile.as_video_stream_profile().intrinsics\n",
    "\n",
    "        for r in range(0, num_rows, 5):\n",
    "            for c in range(0, num_cols, 5):\n",
    "                depth = aligned_depth_frame.get_distance(c, r)\n",
    "                depth_point_in_meters_camera_coords = rs.rs2_deproject_pixel_to_point(depth_intrin, [c, r], depth)\n",
    "                #some other stuff I do here with this depth point, such as projecting it to world coordinates etc.\n",
    "\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "model_path2=FROOT+\"\\muctdata\\models\\MUCTmodel_3con_2fc_b36_e100_aug_lrdec_mominc_dr\\model.ckpt\"\n",
    "Image_loc=\"image1_3.jpg\"\n",
    "img=Image.open(Image_loc).convert('LA')\n",
    "img.show()\n",
    "img_arr=np.array(img)[:,:,0]\n",
    "img_arrnormal=img_arr/255\n",
    "X = img_arrnormal.astype(np.float32)\n",
    "XR=X.reshape(-1,Irows,Icols,1)\n",
    "pred=[]\n",
    "\n",
    "with tf.Session(graph = graph) as sess:\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess,model_path2)\n",
    "    print(\"model restored\")\n",
    "    pred=sess.run([predictions], feed_dict = {\n",
    "                tf_x_batch : XR,\n",
    "                is_training : False\n",
    "            }\n",
    "                    )\n",
    "print(\"prediction are: \" + str(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleyinv(y,rows,cols):\n",
    "    #loop for rows\n",
    "    dr=cols/2\n",
    "    for i in range(0,152,2):\n",
    "        y[i]=(y[i]*dr)+dr\n",
    "    #loop for cols\n",
    "    dc=rows/2\n",
    "    for i in range(1,152,2):\n",
    "        y[i]=(y[i]*dc)+dc\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152,)\n",
      "[-4.09757018e-01  9.70426947e-03 -4.20393825e-01  1.00986220e-01\n",
      " -4.03695345e-01  1.92281395e-01 -3.94951820e-01  2.89573044e-01\n",
      " -3.33921462e-01  3.90932828e-01 -2.47292325e-01  4.63322341e-01\n",
      " -1.32102624e-01  4.98232961e-01 -2.77678668e-03  5.16548872e-01\n",
      "  1.22197241e-01  4.99967843e-01  2.39044249e-01  4.56127167e-01\n",
      "  3.28049630e-01  3.96210134e-01  3.85517359e-01  2.95656800e-01\n",
      "  4.05359030e-01  1.99052751e-01  4.10661906e-01  1.06420457e-01\n",
      "  4.05348420e-01  9.70695913e-03  3.07913005e-01 -4.51300740e-02\n",
      "  2.36076683e-01 -1.00042708e-01  1.64960876e-01 -1.07555471e-01\n",
      "  8.51064250e-02 -6.33961558e-02  1.67819902e-01 -7.34384358e-02\n",
      "  2.39568233e-01 -7.12789744e-02 -3.32991898e-01 -5.75358644e-02\n",
      " -2.65245497e-01 -1.12159632e-01 -1.78951755e-01 -9.77146626e-02\n",
      " -9.47979391e-02 -7.50247240e-02 -1.68786347e-01 -6.14172891e-02\n",
      " -2.60976851e-01 -6.40557706e-02 -2.69603133e-01  1.06885955e-02\n",
      " -2.01534361e-01 -3.11491489e-02 -1.36702031e-01 -7.06210732e-03\n",
      " -1.96867496e-01  2.20097080e-02 -2.04457238e-01 -3.62962484e-03\n",
      "  2.58351833e-01  6.42723963e-03  1.85470685e-01 -2.33246684e-02\n",
      "  1.20386943e-01  1.62643753e-02  1.83466583e-01  2.01166198e-02\n",
      "  1.75920084e-01 -1.80064514e-03 -5.19161709e-02 -2.08392739e-03\n",
      " -6.64531738e-02  8.73062313e-02 -1.32061288e-01  1.46471098e-01\n",
      " -1.02921456e-01  1.72387436e-01 -4.98878676e-03  1.89114764e-01\n",
      "  8.46907645e-02  1.78072408e-01  1.24047495e-01  1.60107255e-01\n",
      "  4.91597354e-02  7.61038586e-02  3.67684551e-02 -8.58761743e-03\n",
      " -6.68794215e-02  1.62906080e-01  5.44364527e-02  1.67027846e-01\n",
      " -1.70320570e-01  2.92100072e-01 -8.56053531e-02  2.48706624e-01\n",
      " -3.82498689e-02  2.44515300e-01 -9.85339284e-04  2.53053755e-01\n",
      "  3.32755595e-02  2.38595724e-01  8.30364153e-02  2.47503877e-01\n",
      "  1.64275065e-01  2.90770352e-01  1.12284400e-01  3.23978782e-01\n",
      "  5.86448647e-02  3.38133574e-01 -7.24326819e-05  3.40419888e-01\n",
      " -6.27292916e-02  3.35660160e-01 -1.24834687e-01  3.27322513e-01\n",
      " -7.44893625e-02  3.00749660e-01 -3.60791618e-03  3.05242926e-01\n",
      "  6.36582449e-02  3.05467218e-01  6.20831288e-02  2.75687933e-01\n",
      "  3.59946163e-04  2.71076620e-01 -7.22288936e-02  2.77124465e-01\n",
      " -6.81039877e-03  2.80366719e-01 -1.04997978e-02  1.32265121e-01\n",
      " -2.40868241e-01 -1.23999119e-02 -1.68547601e-01 -3.69096547e-03\n",
      " -1.59309924e-01  1.35916397e-02 -2.34984308e-01  9.64641571e-03\n",
      "  2.10826397e-01 -1.13646574e-02  1.50747448e-01 -1.01066865e-02\n",
      "  1.42133027e-01  8.14022869e-03  2.18659446e-01  1.50137395e-02]\n"
     ]
    }
   ],
   "source": [
    "npred=np.array(pred[0][0])\n",
    "print(npred.shape)\n",
    "print(npred)\n",
    "#print(str(pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[141.65831 323.10538 139.10548 352.31558 143.11311 381.53006 145.21156\n",
      " 412.66336 159.85886 445.0985  180.64984 468.26315 208.29536 479.43454\n",
      " 239.33357 485.29565 269.32733 479.98972 297.3706  465.9607  318.7319\n",
      " 446.78723 332.52417 414.61017 337.28616 383.69687 338.55887 354.05453\n",
      " 337.28363 323.10623 313.8991  305.55838 296.65842 287.98633 279.5906\n",
      " 285.58224 260.42554 299.71323 280.27676 296.4997  297.49637 297.19073\n",
      " 160.08194 301.58853 176.34108 284.10892 197.05157 288.73132 217.24849\n",
      " 295.9921  199.49127 300.34647 177.36555 299.50217 175.29524 323.42035\n",
      " 191.63176 310.0323  207.19151 317.7401  192.7518  327.04312 190.93027\n",
      " 318.83853 302.00443 322.0567  284.51297 312.5361  268.89285 325.2046\n",
      " 284.03198 326.43732 282.22083 319.4238  227.54012 319.33313 224.05124\n",
      " 347.938   208.3053  366.87076 215.29884 375.16397 238.80269 380.51672\n",
      " 260.32578 376.9832  269.7714  371.2343  251.79834 344.35324 248.82443\n",
      " 317.25195 223.94894 372.12994 253.06474 373.4489  199.12306 413.47202\n",
      " 219.45471 399.58612 230.82004 398.2449  239.76352 400.9772  247.98613\n",
      " 396.35065 259.92874 399.20123 279.42603 413.0465  266.94824 423.67322\n",
      " 254.07477 428.20276 239.98262 428.93436 224.94498 427.41125 210.03967\n",
      " 424.7432  222.12256 416.2399  239.1341  417.67773 255.27798 417.7495\n",
      " 254.89995 408.22015 240.08638 406.7445  222.66507 408.67984 238.36551\n",
      " 409.71735 237.48004 362.32483 182.19162 316.03204 199.54857 318.81888\n",
      " 201.76562 324.34933 183.60376 323.08685 290.59833 316.3633  276.17938\n",
      " 316.76587 274.11194 322.60486 292.47827 324.80438]\n"
     ]
    }
   ],
   "source": [
    "oupred=scaleyinv(npred,Irows,Icols)\n",
    "print(oupred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oupred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nop=np.floor(oupred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[141. 323. 139. 352. 143. 381. 145. 412. 159. 445. 180. 468. 208. 479.\n",
      " 239. 485. 269. 479. 297. 465. 318. 446. 332. 414. 337. 383. 338. 354.\n",
      " 337. 323. 313. 305. 296. 287. 279. 285. 260. 299. 280. 296. 297. 297.\n",
      " 160. 301. 176. 284. 197. 288. 217. 295. 199. 300. 177. 299. 175. 323.\n",
      " 191. 310. 207. 317. 192. 327. 190. 318. 302. 322. 284. 312. 268. 325.\n",
      " 284. 326. 282. 319. 227. 319. 224. 347. 208. 366. 215. 375. 238. 380.\n",
      " 260. 376. 269. 371. 251. 344. 248. 317. 223. 372. 253. 373. 199. 413.\n",
      " 219. 399. 230. 398. 239. 400. 247. 396. 259. 399. 279. 413. 266. 423.\n",
      " 254. 428. 239. 428. 224. 427. 210. 424. 222. 416. 239. 417. 255. 417.\n",
      " 254. 408. 240. 406. 222. 408. 238. 409. 237. 362. 182. 316. 199. 318.\n",
      " 201. 324. 183. 323. 290. 316. 276. 316. 274. 322. 292. 324.]\n"
     ]
    }
   ],
   "source": [
    "print(nop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[141. 323.]\n",
      " [139. 352.]\n",
      " [143. 381.]\n",
      " [145. 412.]\n",
      " [159. 445.]\n",
      " [180. 468.]\n",
      " [208. 479.]\n",
      " [239. 485.]\n",
      " [269. 479.]\n",
      " [297. 465.]\n",
      " [318. 446.]\n",
      " [332. 414.]\n",
      " [337. 383.]\n",
      " [338. 354.]\n",
      " [337. 323.]\n",
      " [313. 305.]\n",
      " [296. 287.]\n",
      " [279. 285.]\n",
      " [260. 299.]\n",
      " [280. 296.]\n",
      " [297. 297.]\n",
      " [160. 301.]\n",
      " [176. 284.]\n",
      " [197. 288.]\n",
      " [217. 295.]\n",
      " [199. 300.]\n",
      " [177. 299.]\n",
      " [175. 323.]\n",
      " [191. 310.]\n",
      " [207. 317.]\n",
      " [192. 327.]\n",
      " [190. 318.]\n",
      " [302. 322.]\n",
      " [284. 312.]\n",
      " [268. 325.]\n",
      " [284. 326.]\n",
      " [282. 319.]\n",
      " [227. 319.]\n",
      " [224. 347.]\n",
      " [208. 366.]\n",
      " [215. 375.]\n",
      " [238. 380.]\n",
      " [260. 376.]\n",
      " [269. 371.]\n",
      " [251. 344.]\n",
      " [248. 317.]\n",
      " [223. 372.]\n",
      " [253. 373.]\n",
      " [199. 413.]\n",
      " [219. 399.]\n",
      " [230. 398.]\n",
      " [239. 400.]\n",
      " [247. 396.]\n",
      " [259. 399.]\n",
      " [279. 413.]\n",
      " [266. 423.]\n",
      " [254. 428.]\n",
      " [239. 428.]\n",
      " [224. 427.]\n",
      " [210. 424.]\n",
      " [222. 416.]\n",
      " [239. 417.]\n",
      " [255. 417.]\n",
      " [254. 408.]\n",
      " [240. 406.]\n",
      " [222. 408.]\n",
      " [238. 409.]\n",
      " [237. 362.]\n",
      " [182. 316.]\n",
      " [199. 318.]\n",
      " [201. 324.]\n",
      " [183. 323.]\n",
      " [290. 316.]\n",
      " [276. 316.]\n",
      " [274. 322.]\n",
      " [292. 324.]]\n"
     ]
    }
   ],
   "source": [
    "nop1=np.reshape(nop,(76,2))\n",
    "print(nop1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1598440cfd0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig2 = pyplot.figure(figsize=(6, 3))\n",
    "axis = fig2.add_subplot(1, 2, 1, xticks=[], yticks=[])\n",
    "oimg=XR.reshape(Irows,Icols)\n",
    "axis.imshow(oimg, cmap='gray')\n",
    "axis.scatter(nop[0::2], nop[1::2], marker='x', s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
